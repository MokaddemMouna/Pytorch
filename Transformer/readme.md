First, I read the original [paper](https://arxiv.org/abs/1706.03762).

Then I followed Jal Ammar's [blog](http://jalammar.github.io/illustrated-transformer/?fbclid=IwAR0X177SwjRj01Hc_BGBfhX8NINgnZFzZxMbfG16xVQuuUhxlfWWXnZ9TJM) to understand more concepts.

And I followed the Alexander Rush's blog called [**Annotated Transformer**](http://nlp.seas.harvard.edu/2018/04/03/attention.html).
